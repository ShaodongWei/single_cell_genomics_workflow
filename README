# Snakemake Single-Cell Sequencing Workflow
## Overview
This pipeline is designed to preprocess single-cell sequencing data by handling demultiplexing, pruning based on read thresholds, calculating demultiplexed read percentages, quality control, mapping reads to a reference, and analyzing depth coverage.

# Getting Started
## Prerequisites
### Before using the pipeline, ensure you have the following installed:

Snakemake: [Installation guide](https://snakemake.readthedocs.io/en/stable/getting_started/installation.html) 

conda: installation guide (https://conda.io/projects/conda/en/latest/user-guide/install/index.html) 

# How to Use the Pipeline
## 1. Clone the Repository
First, clone the repository containing the Snakemake pipeline to your local machine:

```bash
git clone https://github.com/ShaodongWei/single_cell_sequencing_workflow.git

```
## 2. Set up the configuration file 

```functions: "/path/to/functions.sh" # functions for analysis 

fastq1: "/path/to/data/KP_R1.fastq" #input fastq files 

fastq2: "/path/to/data/KP_R2.fastq" #input fastq files

output_directory: "/path/to/snakemake/output" #directory where results will be saved  

barcode1: "/path/to/snakemake/barcode/barcode3.fa" #barcode files, here our program is designed to process 3 tandem barcodes, and the barcode is on the R2 fastq file. 

barcode2: "/path/to/snakemake/barcode/barcode2.fa"

barcode3: "/path/to/snakemake/barcode/barcode1.fa"

primer: "/path/to/snakemake/primer/primer.fa" #primer file

reference: "/path/to/snakemake/reference_plas/KP_fa" # reference genome where the reads will be mapped against to calculate depth, coverage. Reference name has to be "_" separated. 

# threads to use, better to be same as the specified in snakemake --cores <threads>
threads: 4

# prune samples based on R1+R2 reads 
min_reads: 10
max_reads: 

# cutadapt 
cutadapt_error_rate: 0.125
cutadapt_overlap_minlength: 8

# trimmomatic average quality with the sliding windows
trimmomatic_quality : 15
```



## 3. Run the pipeline using snakemake

conda config --set channel_priority flexible # set channel priority to be flexible for conda

### Run the entire pipeline 
snakemake --cores threads_number --use-conda  # conda will install dependencies into isolated environment for each step. All steps will be executed sequentially. 

### Run a specific step 
snakemake --list # to show steps

snakemake step_name --cores threads_number --use-conda

## 4. Steps in the workflow 
### Step 1, demultiplexing
This step is to demultiplex your single raw fastq files into barcoded single cell files that each file ideally represents a single droplet. You have to use 3 tandem barcode files that are allocated on the R2 file. The workflow can easily be modified to support the condition that barcode are on the R1 file or both. 
### Step 2, prune demultiplexed files based on R1 + R2 number of reads
This step is to choose the range of sequence depth, where you can specify minimal reads (leave parameter max_reads empty), maximal reads (leave parameter min_reads empty), or between minimal and maximal reads (specify both min_reads and max_reads). 
### Step 3, calculate the percentage of reads successfully demultiplexed
This step is to report the percentage of reads that are successfully demultiplexed, before applying the pruning of reads. 
### Step 4, quality control 
This step is to quality control the reads using the trimmomatic software using the default parameters for paired-end fastq files 'ILLUMINACLIP:{your_primer}:2:30:10:2:True LEADING:3 TRAILING:3 SLIDINGWINDOW:4:{your.specified.trimmomatic_quality} MINLEN:30', and users have to specify your own primer used and the average per base quality score in the sliding window. 
### Step 5, mapping reads to reference 
This step is to map each barcoded fastq files to the reference. Users can choose to use bwa-mem2 (https://github.com/bwa-mem2/bwa-mem2) as the mapper for general purposes, or the kma (https://bitbucket.org/genomicepidemiology/kma/src/master/) as the mapper when the references have similar genomes or redundant.
### Step 6, calculate depth and coverage (positions covered by reads in percentage) for each reference contig and each barcode file 
This step first calculates depth for each position in the contigs from the reference, then calculate the coverage for each reference contig. The it also reports the percentage of positions that each barcode file can cover in the reference (coverage). 









